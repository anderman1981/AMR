# üìöüß† AMROIS 2.0 - Sistema Multi-Agente Coach Literario

## Especificaci√≥n T√©cnica para Evoluci√≥n del Sistema Actual

---

## 1. An√°lisis del Estado Actual

### 1.1 Fortalezas de AMROIS 1.0 ‚úÖ

**Stack T√©cnico S√≥lido:**
- ‚úÖ Node.js + Express (backend funcional)
- ‚úÖ React + Vite + Ant Design (UI moderna)
- ‚úÖ SQLite (base de datos operativa)
- ‚úÖ Ollama + LLaMA 3 (IA local, sin costos)
- ‚úÖ Sistema de agentes en background (base para extensi√≥n)

**Funcionalidades Core:**
- ‚úÖ Gesti√≥n multi-formato (PDF, EPUB, MOBI, TXT, DOCX)
- ‚úÖ Extracci√≥n de texto automatizada
- ‚úÖ RAG b√°sico implementado
- ‚úÖ Chat por libro y global
- ‚úÖ An√°lisis con IA (res√∫menes, insights, citas)
- ‚úÖ Extracci√≥n de formularios interactivos

### 1.2 √Åreas de Mejora üéØ

**Limitaciones Actuales:**
- ‚ùå Respuestas tipo "resumen acad√©mico", no conversaci√≥n
- ‚ùå An√°lisis superficial (no aplica frameworks profundos)
- ‚ùå Sin memoria contextual entre sesiones
- ‚ùå Sin aprendizaje de preferencias del usuario
- ‚ùå RAG b√°sico (chunking por caracteres, no sem√°ntico)
- ‚ùå Una sola "voz", no adaptada por autor

**Objetivo AMROIS 2.0:**
Transformar de **"biblioteca con IA"** a **"coach literario personalizado"**

---

## 2. Arquitectura de Evoluci√≥n (sin romper lo actual)

### 2.1 Principios de Migraci√≥n

```
‚úÖ MANTENER: Backend Express, SQLite, Ollama, React UI
‚úÖ AGREGAR: n8n (orquestaci√≥n), TensorFlow.js (ML), Chroma (vector store)
‚úÖ MEJORAR: RAG, prompts, an√°lisis, narrativa
‚úÖ NO ROMPER: Funcionalidades actuales durante transici√≥n
```

### 2.2 Arquitectura Propuesta

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ              AMROIS 2.0 - Frontend (React)                   ‚îÇ
‚îÇ  Mantiene: Dashboard, Lector, Chat UI existente             ‚îÇ
‚îÇ  Agrega: Feedback stars, indicador multi-agente             ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                     ‚îÇ
                     ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ         API Gateway (Express - ACTUAL)                       ‚îÇ
‚îÇ  Rutas actuales:                                            ‚îÇ
‚îÇ  - /api/books (CRUD) ‚úÖ SE MANTIENE                         ‚îÇ
‚îÇ  - /api/chat/book/:id ‚úÖ SE MEJORA                          ‚îÇ
‚îÇ  - /api/chat/global ‚úÖ SE MEJORA                            ‚îÇ
‚îÇ  - /api/analysis ‚úÖ SE MANTIENE                             ‚îÇ
‚îÇ  Rutas nuevas:                                              ‚îÇ
‚îÇ  + /api/chat/feedback (para ML)                             ‚îÇ
‚îÇ  + /api/agents/status (monitoreo)                           ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                     ‚îÇ
         ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
         ‚ñº                          ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê       ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ   SQLite DB      ‚îÇ       ‚îÇ   Chroma Vector DB   ‚îÇ
‚îÇ   (ACTUAL)       ‚îÇ       ‚îÇ   (NUEVO)            ‚îÇ
‚îÇ  ‚úÖ books        ‚îÇ       ‚îÇ  + Embeddings        ‚îÇ
‚îÇ  ‚úÖ analysis     ‚îÇ       ‚îÇ  + Chunks sem√°nticos ‚îÇ
‚îÇ  ‚úÖ messages     ‚îÇ       ‚îÇ  + Metadatos         ‚îÇ
‚îÇ  + ml_training   ‚îÇ       ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
‚îÇ  + gap_memory    ‚îÇ
‚îÇ  + metrics       ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
         ‚îÇ
         ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ              n8n - Orquestador (NUEVO)                       ‚îÇ
‚îÇ                                                              ‚îÇ
‚îÇ  Workflow: Chat con Coach                                    ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê   ‚îÇ
‚îÇ  ‚îÇ Agent 1  ‚îÇ‚Üí ‚îÇ Agent 2  ‚îÇ‚Üí ‚îÇ Agent 3  ‚îÇ‚Üí ‚îÇ Agent 4  ‚îÇ‚Üí  ‚îÇ
‚îÇ  ‚îÇInterpret ‚îÇ  ‚îÇExtractor ‚îÇ  ‚îÇ Analyzer ‚îÇ  ‚îÇSynthesis ‚îÇ   ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò   ‚îÇ
‚îÇ                                      ‚Üì                       ‚îÇ
‚îÇ                              ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê               ‚îÇ
‚îÇ                              ‚îÇ   Agent 5    ‚îÇ               ‚îÇ
‚îÇ                              ‚îÇ   Narrator   ‚îÇ               ‚îÇ
‚îÇ                              ‚îÇ   (Coach)    ‚îÇ               ‚îÇ
‚îÇ                              ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò               ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                     ‚îÇ
         ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
         ‚ñº                       ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ  Ollama (ACTUAL) ‚îÇ    ‚îÇ  TensorFlow.js (NEW) ‚îÇ
‚îÇ  localhost:11434 ‚îÇ    ‚îÇ  - Intent Classifier ‚îÇ
‚îÇ  LLaMA 3.1:70b   ‚îÇ    ‚îÇ  - Style Transfer    ‚îÇ
‚îÇ                  ‚îÇ    ‚îÇ  - Feedback Learning ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
         ‚îÇ
         ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ         GAP Protocol - Memoria de Agentes (NUEVO)             ‚îÇ
‚îÇ  - S√≠ntesis exitosas (rating 4-5)                            ‚îÇ
‚îÇ  - Patrones de conversaci√≥n efectivos                        ‚îÇ
‚îÇ  - Preferencias de usuario por contexto                      ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

---

## 3. Sistema Multi-Agente Detallado

### 3.1 Agent 1: Interpreter (Clasificador de Intenci√≥n)

**Integraci√≥n con c√≥digo actual:**

```javascript
// backend/routes/chat.js (MODIFICAR - agregar capa intermedia)

const express = require('express');
const router = express.Router();
const db = require('../database');

// NUEVO: Feature flag para activar/desactivar pipeline multi-agente
const USE_MULTI_AGENT = process.env.USE_MULTI_AGENT === 'true';

router.post('/chat/book/:id', async (req, res) => {
  const { message } = req.body;
  const bookId = req.params.id;
  
  try {
    // NUEVO: Si multi-agente est√° activo, interpretar primero
    if (USE_MULTI_AGENT) {
      const interpretation = await interpretUserIntent(message, bookId, req.session);
      
      // Si no hay claridad suficiente, hacer preguntas
      if (!interpretation.claridad_suficiente) {
        return res.json({
          type: 'clarification',
          questions: interpretation.preguntas_aclaracion,
          interpretation_id: interpretation.id
        });
      }
      
      // Si hay claridad, ejecutar pipeline completo
      const response = await executeMultiAgentPipeline(interpretation, message, bookId);
      return res.json(response);
    }
    
    // ACTUAL: Flujo original (fallback)
    const book = await db.get('SELECT * FROM books WHERE id = ?', [bookId]);
    const context = await buildRAGContext(message, book.extracted_text);
    const ollamaResponse = await callOllama(message, context);
    
    // Guardar mensaje
    await db.run(
      'INSERT INTO messages (book_id, role, content, created_at) VALUES (?, ?, ?, ?)',
      [bookId, 'assistant', ollamaResponse, Date.now()]
    );
    
    res.json({ 
      response: ollamaResponse,
      type: 'direct' 
    });
    
  } catch (error) {
    console.error('Error en chat:', error);
    res.status(500).json({ error: 'Error al procesar mensaje' });
  }
});

// NUEVA FUNCI√ìN: Interpretar intenci√≥n del usuario
async function interpretUserIntent(message, bookId, session) {
  // Llamar a n8n webhook que ejecuta Agent 1
  const response = await fetch('http://localhost:5678/webhook/interpret', {
    method: 'POST',
    headers: { 'Content-Type': 'application/json' },
    body: JSON.stringify({
      message,
      bookId,
      conversationHistory: session.conversationHistory || [],
      userProfile: session.userProfile || {}
    })
  });
  
  return await response.json();
}

// NUEVA FUNCI√ìN: Ejecutar pipeline completo
async function executeMultiAgentPipeline(interpretation, message, bookId) {
  // Llamar a n8n workflow master que orquesta todos los agentes
  const response = await fetch('http://localhost:5678/webhook/full-pipeline', {
    method: 'POST',
    headers: { 'Content-Type': 'application/json' },
    body: JSON.stringify({
      interpretation,
      originalMessage: message,
      bookId
    })
  });
  
  const result = await response.json();
  
  // Guardar respuesta con metadata para tracking
  await db.run(`
    INSERT INTO messages (
      book_id, 
      role, 
      content, 
      metadata,
      created_at
    ) VALUES (?, ?, ?, ?, ?)
  `, [
    bookId,
    'assistant',
    result.narrative_response,
    JSON.stringify({
      synthesis_id: result.synthesis_id,
      interpretation: interpretation,
      voice_profile: result.voice_profile
    }),
    Date.now()
  ]);
  
  return {
    type: 'narrative',
    response: result.narrative_response,
    synthesis_id: result.synthesis_id,
    next_question: result.next_question
  };
}

module.exports = router;
```

**Prompt para Agent 1 (via n8n + Ollama):**

```javascript
// backend/prompts/interpreter.js

function buildInterpreterPrompt(userMessage, context) {
  return `Eres un experto en an√°lisis de intenciones conversacionales sobre libros.

CONTEXTO DEL USUARIO:
- Libro actual: "${context.bookTitle}" por ${context.bookAuthor}
- Historial: ${context.conversationHistory.length} mensajes previos
${context.conversationHistory.length > 0 ? `- √öltimo tema: ${context.conversationHistory.slice(-1)[0].topic}` : ''}

MENSAJE DEL USUARIO:
"${userMessage}"

ANALIZA Y CLASIFICA:

1. OBJETIVO principal (selecciona UNO):
   - "aprender": Quiere entender conceptos, ideas, teor√≠as del libro
   - "decidir": Necesita ayuda para tomar una decisi√≥n usando el conocimiento
   - "crear": Quiere dise√±ar algo nuevo (plan, sistema, estrategia)
   - "aplicar": Busca pasos concretos para implementar en su vida
   - "investigar": Quiere comparar con otros libros o profundizar m√°s
   - "reflexionar": Busca pensar m√°s profundo sobre un tema filos√≥fico

2. CLARIDAD del mensaje (¬øpuedes responder bien con esta info?):
   - true: El mensaje es suficientemente espec√≠fico
   - false: Necesitas hacer 2-4 preguntas cortas de aclaraci√≥n

3. PROFUNDIDAD esperada por el usuario:
   - "rapida": Quiere respuesta directa (1-2 min de lectura)
   - "practica": Quiere acciones concretas (3-5 min)
   - "profunda": Quiere an√°lisis detallado (5-10 min)
   - "estrategica": Quiere framework completo (10+ min)

4. CONTEXTO detectado:
   - tema_principal: ¬øDe qu√© trata espec√≠ficamente?
   - subtemas: ¬øQu√© otros temas relacionados implica?
   - nivel_usuario: principiante/intermedio/avanzado (basado en c√≥mo pregunta)

5. Si claridad es FALSE, genera 2-4 PREGUNTAS CORTAS como:
   - "¬øPara qu√© situaci√≥n espec√≠fica quieres aplicar esto?"
   - "¬øPrefieres enfoque pr√°ctico o estrat√©gico?"
   - "¬øHay alg√∫n desaf√≠o particular que enfrentas con esto?"

RESPONDE SOLO EN JSON (sin markdown, sin comentarios):
{
  "objetivo": "aprender|decidir|crear|aplicar|investigar|reflexionar",
  "claridad_suficiente": true|false,
  "profundidad": "rapida|practica|profunda|estrategica",
  "contexto_detectado": {
    "tema_principal": "...",
    "subtemas": ["...", "..."],
    "nivel_usuario": "principiante|intermedio|avanzado"
  },
  "preguntas_aclaracion": ["...", "..."],
  "confianza": 0.85
}`;
}

module.exports = { buildInterpreterPrompt };
```

**n8n Workflow para Agent 1:**

```json
{
  "name": "AMROIS - Agent 1 Interpreter",
  "nodes": [
    {
      "parameters": {
        "httpMethod": "POST",
        "path": "interpret",
        "responseMode": "responseNode"
      },
      "name": "Webhook Trigger",
      "type": "n8n-nodes-base.webhook",
      "position": [240, 300],
      "id": "webhook-1"
    },
    {
      "parameters": {
        "method": "POST",
        "url": "http://localhost:11434/api/generate",
        "options": {},
        "bodyParametersJson": "={\n  \"model\": \"llama3.1:70b\",\n  \"prompt\": \"{{ $json.interpretPrompt }}\",\n  \"stream\": false,\n  \"format\": \"json\",\n  \"options\": {\n    \"temperature\": 0.3,\n    \"top_p\": 0.9\n  }\n}"
      },
      "name": "Ollama - Interpret",
      "type": "n8n-nodes-base.httpRequest",
      "position": [460, 300],
      "id": "ollama-1"
    },
    {
      "parameters": {
        "functionCode": "// Parsear respuesta de Ollama\nconst ollamaResponse = JSON.parse($input.item.json.response);\n\n// Agregar ID √∫nico para tracking\nollamaResponse.id = `interpret_${Date.now()}_${Math.random().toString(36).substr(2, 9)}`;\n\nreturn { json: ollamaResponse };"
      },
      "name": "Parse Response",
      "type": "n8n-nodes-base.code",
      "position": [680, 300],
      "id": "code-1"
    },
    {
      "parameters": {
        "conditions": {
          "boolean": [
            {
              "value1": "={{ $json.claridad_suficiente }}",
              "value2": true
            }
          ]
        }
      },
      "name": "IF - Claridad OK?",
      "type": "n8n-nodes-base.if",
      "position": [900, 300],
      "id": "if-1"
    },
    {
      "parameters": {
        "respondWith": "json",
        "responseBody": "={{ $json }}"
      },
      "name": "Respond - Need Clarification",
      "type": "n8n-nodes-base.respondToWebhook",
      "position": [900, 480],
      "id": "respond-clarification"
    },
    {
      "parameters": {
        "method": "POST",
        "url": "http://localhost:3464/api/agents/log-interpretation",
        "bodyParametersJson": "={{ $json }}"
      },
      "name": "Log to Database",
      "type": "n8n-nodes-base.httpRequest",
      "position": [1120, 300],
      "id": "log-db"
    },
    {
      "parameters": {
        "respondWith": "json",
        "responseBody": "={{ $json }}"
      },
      "name": "Respond - Success",
      "type": "n8n-nodes-base.respondToWebhook",
      "position": [1340, 300],
      "id": "respond-success"
    }
  ],
  "connections": {
    "Webhook Trigger": {
      "main": [[{"node": "Ollama - Interpret"}]]
    },
    "Ollama - Interpret": {
      "main": [[{"node": "Parse Response"}]]
    },
    "Parse Response": {
      "main": [[{"node": "IF - Claridad OK?"}]]
    },
    "IF - Claridad OK?": {
      "main": [
        [{"node": "Log to Database"}],
        [{"node": "Respond - Need Clarification"}]
      ]
    },
    "Log to Database": {
      "main": [[{"node": "Respond - Success"}]]
    }
  }
}
```

---

### 3.2 Agent 2: Extractor (Mejorado con Vector Store)

**Migraci√≥n de RAG actual a Chroma:**

```javascript
// backend/services/vectorStore.js (NUEVO - reemplaza RAG b√°sico)

const { ChromaClient } = require('chromadb');
const ollama = require('../utils/ollama');

class VectorStoreService {
  constructor() {
    this.client = new ChromaClient({ path: 'http://localhost:8000' });
    this.collection = null;
  }
  
  async initialize() {
    try {
      this.collection = await this.client.getOrCreateCollection({
        name: 'amrois_books',
        metadata: { 
          'hnsw:space': 'cosine',
          description: 'AMROIS book embeddings with semantic chunking'
        }
      });
      console.log('‚úÖ Vector store initialized');
    } catch (error) {
      console.error('‚ùå Error initializing vector store:', error);
      throw error;
    }
  }
  
  /**
   * Indexar un libro completo con chunking inteligente
   * MEJORA vs actual: chunks sem√°nticos en vez de por caracteres
   */
  async indexBook(bookId, bookText, metadata) {
    console.log(`üìä Indexando libro: ${metadata.title}`);
    
    // Chunking inteligente (por secciones, no por caracteres fijos)
    const chunks = await this.intelligentChunking(bookText, metadata);
    
    console.log(`  - ${chunks.length} chunks creados`);
    
    // Generar embeddings usando Ollama
    const embeddings = await this.generateEmbeddings(chunks.map(c => c.text));
    
    // Preparar documentos para Chroma
    const ids = chunks.map((_, i) => `${bookId}_chunk_${i}`);
    const documents = chunks.map(c => c.text);
    const metadatas = chunks.map((chunk, i) => ({
      book_id: bookId,
      book_title: metadata.title,
      author: metadata.author,
      chunk_index: i,
      chunk_type: chunk.type,
      page_estimate: chunk.pageEstimate,
      word_count: chunk.wordCount
    }));
    
    // Agregar a Chroma
    await this.collection.add({
      ids,
      embeddings,
      documents,
      metadatas
    });
    
    // Actualizar en SQLite que el libro est√° indexado
    const db = require('../database');
    await db.run(
      'UPDATE books SET vector_indexed = 1, chunks_count = ? WHERE id = ?',
      [chunks.length, bookId]
    );
    
    console.log(`‚úÖ Libro indexado: ${chunks.length} chunks`);
  }
  
  /**
   * Chunking inteligente - MEJORA CLAVE
   * Detecta cap√≠tulos, secciones, cambios de tema
   */
  async intelligentChunking(text, metadata) {
    const chunks = [];
    
    // 1. Detectar cap√≠tulos primero
    const chapterRegex = /(?:Chapter|Cap√≠tulo|CHAPTER|CAP√çTULO)\s+(\d+|[IVXLCDM]+)[:\.]?\s*(.+?)(?=\n|$)/gi;
    const chapters = text.split(chapterRegex);
    
    let currentPage = 1;
    const wordsPerPage = 250; // Estimaci√≥n
    
    for (let i = 0; i < chapters.length; i++) {
      const chapterText = chapters[i];
      
      if (!chapterText || chapterText.trim().length < 100) continue;
      
      // Si el cap√≠tulo es muy largo (>1500 palabras), sub-dividir
      const words = chapterText.trim().split(/\s+/);
      
      if (words.length > 1500) {
        // Sub-dividir por p√°rrafos manteniendo coherencia sem√°ntica
        const paragraphs = chapterText.split(/\n\n+/);
        let currentChunk = '';
        let chunkWordCount = 0;
        
        for (const paragraph of paragraphs) {
          const pWords = paragraph.trim().split(/\s+/).length;
          
          // Si agregar este p√°rrafo excede 800 palabras, guardar chunk actual
          if (chunkWordCount + pWords > 800 && currentChunk.length > 0) {
            chunks.push({
              text: currentChunk.trim(),
              type: this.detectChunkType(currentChunk),
              pageEstimate: currentPage,
              wordCount: chunkWordCount
            });
            
            currentPage += Math.ceil(chunkWordCount / wordsPerPage);
            currentChunk = paragraph;
            chunkWordCount = pWords;
          } else {
            currentChunk += '\n\n' + paragraph;
            chunkWordCount += pWords;
          }
        }
        
        // Agregar √∫ltimo chunk
        if (currentChunk.trim().length > 0) {
          chunks.push({
            text: currentChunk.trim(),
            type: this.detectChunkType(currentChunk),
            pageEstimate: currentPage,
            wordCount: chunkWordCount
          });
          currentPage += Math.ceil(chunkWordCount / wordsPerPage);
        }
      } else {
        // Cap√≠tulo completo como chunk
        chunks.push({
          text: chapterText.trim(),
          type: 'chapter',
          pageEstimate: currentPage,
          wordCount: words.length
        });
        currentPage += Math.ceil(words.length / wordsPerPage);
      }
    }
    
    return chunks;
  }
  
  /**
   * Detectar tipo de secci√≥n (ayuda a priorizar en b√∫squeda)
   */
  detectChunkType(text) {
    const lowerText = text.toLowerCase();
    
    if (/exercise|ejercicio|pr√°ctica|actividad/i.test(text)) return 'exercise';
    if (/summary|resumen|conclusi√≥n|en s√≠ntesis/i.test(text)) return 'summary';
    if (/example|ejemplo|caso|historia|an√©cdota/i.test(text)) return 'example';
    if (/principle|principio|regla|ley|concepto clave/i.test(text)) return 'principle';
    if (/quote|cita|dice|afirma|seg√∫n/i.test(text)) return 'quote';
    
    return 'content';
  }
  
  /**
   * Generar embeddings usando Ollama
   */
  async generateEmbeddings(texts) {
    const embeddings = [];
    
    // Procesar en batches para no saturar Ollama
    const batchSize = 5;
    
    for (let i = 0; i < texts.length; i += batchSize) {
      const batch = texts.slice(i, i + batchSize);
      
      const batchEmbeddings = await Promise.all(
        batch.map(async (text) => {
          const response = await fetch('http://localhost:11434/api/embeddings', {
            method: 'POST',
            headers: { 'Content-Type': 'application/json' },
            body: JSON.stringify({
              model: 'llama3.1:70b',
              prompt: text
            })
          });
          
          const result = await response.json();
          return result.embedding;
        })
      );
      
      embeddings.push(...batchEmbeddings);
      
      // Log progreso
      console.log(`  - Embeddings generados: ${Math.min(i + batchSize, texts.length)}/${texts.length}`);
    }
    
    return embeddings;
  }
  
  /**
   * B√∫squeda mejorada con re-ranking sem√°ntico
   */
  async searchRelevant(query, bookIds = null, options = {}) {
    const {
      limit = 10,
      minSimilarity = 0.5,
      chunkTypes = null // ['principle', 'example', 'summary']
    } = options;
    
    // Generar embedding de la query
    const queryEmbedding = await this.generateEmbeddings([query]);
    
    // Preparar filtros
    let where = {};
    if (bookIds && bookIds.length > 0) {
      where.book_id = { $in: bookIds };
    }
    if (chunkTypes && chunkTypes.length > 0) {
      where.chunk_type = { $in: chunkTypes };
    }
    
    // Buscar en Chroma
    const results = await this.collection.query({
      queryEmbeddings: queryEmbedding,
      nResults: limit * 2, // Traer m√°s para re-ranking
      where: Object.keys(where).length > 0 ? where : undefined
    });
    
    // Re-ranking: priorizar chunks tipo 'principle' y 'summary'
    const ranked = results.ids[0].map((id, i) => ({
      id,
      text: results.documents[0][i],
      metadata: results.metadatas[0][i],
      similarity: 1 - results.distances[0][i], // Convertir distancia a similitud
      boost: this.getTypeBoost(results.metadatas[0][i].chunk_type)
    }));
    
    // Filtrar por similitud m√≠nima y ordenar por score boosted
    const filtered = ranked
      .filter(r => r.similarity >= minSimilarity)
      .map(r => ({
        ...r,
        score: r.similarity * r.boost
      }))
      .sort((a, b) => b.score - a.score)
      .slice(0, limit);
    
    return filtered;
  }
  
  getTypeBoost(chunkType) {
    const boosts = {
      'principle': 1.3,
      'summary': 1.2,
      'example': 1.1,
      'exercise': 1.0,
      'quote': 0.9,
      'content': 1.0
    };
    return boosts[chunkType] || 1.0;
  }
  
  /**
   * Re-indexar libro existente (√∫til para migraciones)
   */
  async reindexBook(bookId) {
    const db = require('../database');
    const book = await db.get('SELECT * FROM books WHERE id = ?', [bookId]);
    
    if (!book || !book.extracted_text) {
      throw new Error(`Libro ${bookId} no encontrado o sin texto extra√≠do`);
    }
    
    // Eliminar chunks antiguos
    await this.collection.delete({
      where: { book_id: bookId }
    });
    
    // Re-indexar
    await this.indexBook(bookId, book.extracted_text, {
      title: book.title,
      author: book.author,
      genre: book.genre
    });
  }
}

module.exports = new VectorStoreService();
```

**Script de migraci√≥n de libros actuales:**

```javascript
// backend/scripts/migrate-to-vector-store.js

const vectorStore = require('../services/vectorStore');
const db = require('../database');

async function migrateAllBooks() {
  console.log('üöÄ Iniciando migraci√≥n de libros a vector store...\n');
  
  // Inicializar Chroma
  await vectorStore.initialize();
  
  // Obtener todos los libros con texto extra√≠do
  const books = await db.all(`
    SELECT id, title, author, genre, extracted_text 
    FROM books 
    WHERE extracted_text IS NOT NULL 
    AND extracted_text != ''
  `);
  
  console.log(`üìö Encontrados ${books.length} libros para migrar\n`);
  
  let success = 0;
  let failed = 0;
  
  for (const book of books) {
    try {
      console.log(`\nüìñ Migrando: "${book.title}" (${book.author})`);
      
      await vectorStore.indexBook(book.id, book.extracted_text, {
        title: book.title,
        author: book.author,
        genre: book.genre
      });
      
      success++;
      console.log(`‚úÖ Migrado exitosamente`);
      
    } catch (error) {
      failed++;
      console.error(`‚ùå Error migrando "${book.title}":`, error.message);
    }
  }
  
  console.log(`\nüìä Resumen:`);
  console.log(`  ‚úÖ Exitosos: ${success}`);
  console.log(`  ‚ùå Fallidos: ${failed}`);
  console.log(`  üìà Total: ${books.length}`);
}

// Ejecutar
migrateAllBooks()
  .then(() => {
    console.log('\nüéâ Migraci√≥n completada');
    process.exit(0);
  })
  .catch(error => {
    console.error('\nüí• Error fatal:', error);
    process.exit(1);
  });
```

**Uso en Agent 2 (Extractor):**

```javascript
// backend/services/agents/extractor.js

const vectorStore = require('../vectorStore');
const ollama = require('../../utils/ollama');

class ExtractorAgent {
  
  async extract(interpretation, message, bookId) {
    console.log(`üîç Extractor Agent ejecutando...`);
    
    // 1. Buscar chunks relevantes con el nuevo vector store
    const relevantChunks = await vectorStore.searchRelevant(
      message,
      [bookId],
      {
        limit: 15,
        minSimilarity: 0.6,
        // Priorizar principios y res√∫menes si el objetivo es "aprender"
        chunkTypes: interpretation.objetivo === 'aprender' 
          ? ['principle', 'summary', 'content']
          : null
      }
    );
    
    console.log(`  - Encontrados ${relevantChunks.length} chunks relevantes`);
    
    // 2. Construir contexto para Ollama
    const context = relevantChunks
      .map((chunk, i) => `
[SECCI√ìN ${i+1} - P√°gina ~${chunk.metadata.page_estimate}]
${chunk.text}
      `)
      .join('\n\n---\n\n');
    
    // 3. Llamar a Ollama para extraer conocimiento estructurado
    const extractionPrompt = this.buildExtractionPrompt(
      message,
      context,
      interpretation
    );
    
    const extraction = await ollama.generate({
      model: 'llama3.1:70b',
      prompt: extractionPrompt,
      format: 'json',
      options: {
        temperature: 0.4,
        num_ctx: 8192 // Contexto amplio para chunks largos
      }
    });
    
    const result = JSON.parse(extraction.response);
    
    // 4. Almacenar extracci√≥n para trazabilidad
    const db = require('../../database');
    await db.run(`
      INSERT INTO extractions (
        book_id,
        query,
        extraction_data,
        chunks_used,
        created_at
      ) VALUES (?, ?, ?, ?, ?)
    `, [
      bookId,
      message,
      JSON.stringify(result),
      relevantChunks.length,
      Date.now()
    ]);
    
    console.log(`‚úÖ Extracci√≥n completada`);
    
    return {
      extraction: result,
      context_chunks: relevantChunks.length,
      avg_similarity: relevantChunks.reduce((acc, c) => acc + c.similarity, 0) / relevantChunks.length
    };
  }
  
  buildExtractionPrompt(userMessage, bookContext, interpretation) {
    return `Eres un experto en extraer conocimiento estructurado de textos.

CONTEXTO DEL LIBRO:
${bookContext}

PREGUNTA DEL USUARIO:
"${userMessage}"

OBJETIVO DEL USUARIO: ${interpretation.objetivo}
PROFUNDIDAD: ${interpretation.profundidad}

EXTRAE del contexto anterior:

1. IDEAS CENTRALES (m√°ximo 5)
   - Solo las ideas m√°s relevantes para la pregunta
   - Con explicaci√≥n concisa
   - Indica en qu√© secci√≥n aparece

2. PRINCIPIOS PR√ÅCTICOS (m√°ximo 7)
   - Formato: "Cuando [situaci√≥n], entonces [acci√≥n]"
   - Que sean aplicables y accionables
   - Basados directamente en el texto

3. MODELOS MENTALES
   - Frameworks o estructuras de pensamiento del autor
   - C√≥mo el autor piensa sobre el tema

4. ARGUMENTOS CLAVE
   - Principales razonamientos del autor
   - Por qu√© funcionan estas ideas

5. CITAS RELEVANTES (m√°ximo 3)
   - Solo las m√°s poderosas para el tema
   - Literales del texto

RESPONDE EN JSON:
{
  "ideas_centrales": [
    {
      "idea": "...",
      "explicacion": "...",
      "seccion": "Secci√≥n 1"
    }
  ],
  "principios_practicos": [
    {
      "cuando": "...",
      "entonces": "...",
      "razon": "..."
    }
  ],
  "modelos_mentales": [
    {
      "nombre": "...",
      "descripcion": "...",
      "cuando_usar": "..."
    }
  ],
  "argumentos_clave": ["...", "..."],
  "citas_relevantes": [
    {
      "texto": "...",
      "contexto": "...",
      "seccion": "Secci√≥n X"
    }
  ]
}`;
  }
}

module.exports = new ExtractorAgent();
```

---

### 3.3 Agent 3: Analyzer (Frameworks de An√°lisis Profundo)

**Implementaci√≥n de Primeros Principios + Feynman:**

```javascript
// backend/services/agents/analyzer.js

const ollama = require('../../utils/ollama');

class AnalyzerAgent {
  
  async analyze(extraction, interpretation) {
    console.log(`üß† Analyzer Agent ejecutando...`);
    
    const analyses = await Promise.all([
      this.applyFirstPrinciples(extraction),
      this.applyFeynman(extraction),
      interpretation.fuentes_requeridas?.length > 1 
        ? this.compareMultipleBooks(extraction) 
        : null
    ]);
    
    return {
      primeros_principios: analyses[0],
      explicaciones_feynman: analyses[1],
      comparacion_libros: analyses[2],
      profundidad_score: this.calculateDepthScore(analyses)
    };
  }
  
  /**
   * Reducci√≥n a Primeros Principios
   */
  async applyFirstPrinciples(extraction) {
    const prompt = `Eres un fil√≥sofo anal√≠tico especializado en reducir ideas a sus primeros principios.

IDEAS EXTRA√çDAS:
${JSON.stringify(extraction.ideas_centrales, null, 2)}

PRINCIPIOS EXTRA√çDOS:
${JSON.stringify(extraction.principios_practicos, null, 2)}

ANALIZA usando el m√©todo de Primeros Principios:

1. Para cada idea/principio, pregunta:
   - ¬øCu√°l es la VERDAD FUNDAMENTAL aqu√≠? (lo que no se puede reducir m√°s)
   - ¬øQu√© SUPUESTOS puedo eliminar sin perder validez?
   - ¬øCu√°l es la ESENCIA irreductible?

2. Identifica:
   - PRIMEROS PRINCIPIOS (verdades base)
   - IDEAS DERIVADAS (construidas sobre los principios)
   - SUPUESTOS ELIMINABLES (contextuales, no esenciales)

3. Valida:
   - ¬øEste principio es universalmente v√°lido o contextual?
   - ¬øQu√© tan fundamental es? (0-100)

RESPONDE EN JSON:
{
  "primeros_principios": [
    {
      "principio": "La √∫nica variable que controlas 100% son tus acciones",
      "ideas_derivadas": ["h√°bitos", "sistemas", "rutinas"],
      "supuestos_eliminados": ["necesitas motivaci√≥n", "requiere fuerza de voluntad"],
      "validez_universal": 90,
      "por_que_es_fundamental": "..."
    }
  ],
  "insights_profundos": ["...", "..."]
}`;

    const response = await ollama.generate({
      model: 'llama3.1:70b',
      prompt,
      format: 'json',
      options: { temperature: 0.3 }
    });
    
    return JSON.parse(response.response);
  }
  
  /**
   * T√©cnica Feynman - Explicar Simple
   */
  async applyFeynman(extraction) {
    const conceptos = [
      ...extraction.ideas_centrales.map(i => i.idea),
      ...extraction.modelos_mentales.map(m => m.nombre)
    ];
    
    const prompt = `Eres Richard Feynman. Tu trabajo es explicar conceptos de forma tan simple que un ni√±o de 12 a√±os lo entienda.

CONCEPTOS A EXPLICAR:
${conceptos.map((c, i) => `${i+1}. ${c}`).join('\n')}

Para cada concepto:

1. EXPLICA como si fuera para un ni√±o de 12 a√±os
   - Sin jerga t√©cnica
   - Con analog√≠as de la vida real
   - Ejemplos concretos

2. IDENTIFICA d√≥nde est√° la complejidad innecesaria
   - ¬øQu√© palabras complicadas se pueden reemplazar?
   - ¬øQu√© partes son esenciales vs decorativas?

3. DETECTA gaps de comprensi√≥n
   - Si no puedes explicarlo simple, ¬øqu√© falta entender?
   - ¬øQu√© pregunta necesitas responder primero?

RESPONDE EN JSON:
{
  "explicaciones_simples": [
    {
      "concepto_original": "...",
      "explicacion_feynman": "...",
      "analogia": "...",
      "ejemplo_cotidiano": "...",
      "complejidad_eliminada": ["t√©rmino X", "concepto Y"],
      "gaps_detectados": ["falta entender Z"],
      "simplicidad_score": 0-100
    }
  ]
}`;

    const response = await ollama.generate({
      model: 'llama3.1:70b',
      prompt,
      format: 'json',
      options: { temperature: 0.5 }
    });
    
    return JSON.parse(response.response);
  }
  
  /**
   * Comparaci√≥n Multi-Libro (si aplica)
   */
  async compareMultipleBooks(extractions) {
    // TODO: Implementar cuando se agregue soporte multi-libro
    return null;
  }
  
  calculateDepthScore(analyses) {
    // Score basado en:
    // - Cantidad de primeros principios identificados
    // - Simplicidad de explicaciones Feynman
    // - Profundidad de gaps detectados
    
    const [fp, feynman] = analyses;
    
    const fpScore = Math.min(100, fp.primeros_principios.length * 15);
    const feynmanScore = feynman.explicaciones_simples.reduce(
      (acc, e) => acc + e.simplicidad_score, 0
    ) / feynman.explicaciones_simples.length;
    
    return Math.round((fpScore + feynmanScore) / 2);
  }
}

module.exports = new AnalyzerAgent();
```

---

### 3.4 Agent 4: Synthesizer (Marco Mental + Acciones)

```javascript
// backend/services/agents/synthesizer.js

const ollama = require('../../utils/ollama');
const gapMemory = require('../gapMemory'); // NUEVO

class SynthesizerAgent {
  
  async synthesize(analysis, interpretation, userContext) {
    console.log(`üéØ Synthesizer Agent ejecutando...`);
    
    // 1. Buscar s√≠ntesis similares exitosas en memoria GAP
    const similarSuccesses = await gapMemory.retrieveSimilar({
      objetivo: interpretation.objetivo,
      profundidad: interpretation.profundidad,
      tema: interpretation.contexto_detectado.tema_principal
    });
    
    // 2. Generar s√≠ntesis usando an√°lisis + memoria
    const synthesis = await this.generateSynthesis(
      analysis,
      interpretation,
      similarSuccesses
    );
    
    // 3. Almacenar en GAP para futuro aprendizaje
    synthesis.id = await gapMemory.storeSynthesis(synthesis, {
      objetivo: interpretation.objetivo,
      tema: interpretation.contexto_detectado.tema_principal
    });
    
    console.log(`‚úÖ S√≠ntesis generada (ID: ${synthesis.id})`);
    
    return synthesis;
  }
  
  async generateSynthesis(analysis, interpretation, similarSuccesses) {
    const prompt = `Eres un maestro en crear frameworks mentales unificados y accionables.

AN√ÅLISIS PROFUNDO:
${JSON.stringify(analysis, null, 2)}

OBJETIVO DEL USUARIO: ${interpretation.objetivo}
PROFUNDIDAD: ${interpretation.profundidad}
NIVEL: ${interpretation.contexto_detectado.nivel_usuario}

${similarSuccesses.length > 0 ? `
S√çNTESIS EXITOSAS SIMILARES (para inspirarte):
${JSON.stringify(similarSuccesses.slice(0, 2), null, 2)}
` : ''}

CREA UNA S√çNTESIS que incluya:

1. S√çNTESIS UNIFICADA (1 p√°rrafo, 100-150 palabras)
   - Integra todas las ideas en un marco coherente
   - Lenguaje simple y directo
   - Sin jerga t√©cnica

2. PRINCIPIOS PR√ÅCTICOS (5-7)
   - Formato: "Cuando [situaci√≥n], entonces [acci√≥n] porque [raz√≥n]"
   - Accionables inmediatamente
   - Verificables en la realidad

3. MARCO MENTAL (diagrama conceptual)
   - C√≥mo se relacionan las ideas entre s√≠
   - En formato mermaid para visualizaci√≥n

4. EXPERIMENTOS DE 72 HORAS (3-5)
   - Acciones peque√±as para implementar en 1-3 d√≠as
   - Espec√≠ficas y concretas
   - Con criterio de √©xito claro
   - Formato: t√≠tulo + pasos + tiempo + resultado esperado

5. PREGUNTAS REFLEXIVAS (2-3)
   - Que inviten a pensar m√°s profundo
   - Sin respuestas obvias
   - Relacionadas con aplicaci√≥n personal

RESPONDE EN JSON:
{
  "sintesis_unificada": "...",
  "principios_practicos": [
    {
      "cuando": "...",
      "entonces": "...",
      "porque": "...",
      "ejemplo": "..."
    }
  ],
  "marco_mental": {
    "diagrama_mermaid": "graph TD; A-->B; B-->C;",
    "explicacion": "..."
  },
  "experimentos_72h": [
    {
      "titulo": "...",
      "descripcion": "...",
      "pasos": ["1. ...", "2. ...", "3. ..."],
      "tiempo_estimado": "30 minutos",
      "criterio_exito": "...",
      "por_que_funciona": "..."
    }
  ],
  "preguntas_reflexivas": [
    "¬øQu√© pasar√≠a si...?",
    "¬øC√≥mo cambiar√≠a tu vida si...?"
  ]
}`;

    const response = await ollama.generate({
      model: 'llama3.1:70b',
      prompt,
      format: 'json',
      options: { 
        temperature: 0.6,
        num_ctx: 8192
      }
    });
    
    return JSON.parse(response.response);
  }
}

module.exports = new SynthesizerAgent();
```

**GAP Memory Service (NUEVO):**

```javascript
// backend/services/gapMemory.js

const db = require('../database');
const crypto = require('crypto');

class GAPMemoryService {
  
  /**
   * Almacenar s√≠ntesis para futuro aprendizaje
   */
  async storeSynthesis(synthesis, context) {
    const id = crypto.randomUUID();
    
    await db.run(`
      INSERT INTO gap_synthesis_memory (
        synthesis_id,
        objetivo,
        tema,
        profundidad,
        sintesis_unificada,
        principios,
        experimentos,
        timestamp,
        user_feedback
      ) VALUES (?, ?, ?, ?, ?, ?, ?, ?, NULL)
    `, [
      id,
      context.objetivo,
      context.tema,
      context.profundidad || 'practica',
      synthesis.sintesis_unificada,
      JSON.stringify(synthesis.principios_practicos),
      JSON.stringify(synthesis.experimentos_72h),
      Date.now()
    ]);
    
    return id;
  }
  
  /**
   * Recuperar s√≠ntesis similares exitosas
   */
  async retrieveSimilar(context, limit = 3) {
    // Buscar s√≠ntesis con mismo objetivo y buen feedback (4-5 estrellas)
    const similar = await db.all(`
      SELECT 
        synthesis_id,
        sintesis_unificada,
        principios,
        experimentos,
        user_feedback
      FROM gap_synthesis_memory
      WHERE objetivo = ?
      AND user_feedback >= 4
      ORDER BY timestamp DESC
      LIMIT ?
    `, [context.objetivo, limit]);
    
    return similar.map(s => ({
      id: s.synthesis_id,
      sintesis: s.sintesis_unificada,
      principios: JSON.parse(s.principios),
      experimentos: JSON.parse(s.experimentos),
      rating: s.user_feedback
    }));
  }
  
  /**
   * Almacenar feedback del usuario
   */
  async storeFeedback(synthesisId, rating, comment = null) {
    await db.run(`
      UPDATE gap_synthesis_memory
      SET 
        user_feedback = ?,
        feedback_comment = ?,
        feedback_timestamp = ?
      WHERE synthesis_id = ?
    `, [rating, comment, Date.now(), synthesisId]);
    
    // Si rating es alto (4-5), marcar como patr√≥n exitoso
    if (rating >= 4) {
      await this.markAsSuccessPattern(synthesisId);
    }
    
    // Si rating es bajo (1-2), analizar para mejorar
    if (rating <= 2) {
      await this.analyzeFailure(synthesisId, comment);
    }
  }
  
  async markAsSuccessPattern(synthesisId) {
    const synthesis = await db.get(
      'SELECT * FROM gap_synthesis_memory WHERE synthesis_id = ?',
      [synthesisId]
    );
    
    // Extraer patr√≥n exitoso
    await db.run(`
      INSERT OR REPLACE INTO gap_success_patterns (
        pattern_type,
        objetivo,
        tema,
        successful_structure,
        times_used,
        avg_rating,
        last_updated
      ) VALUES (?, ?, ?, ?, 
        COALESCE((SELECT times_used + 1 FROM gap_success_patterns 
                  WHERE objetivo = ? AND tema = ?), 1),
        ?, ?)
    `, [
      'synthesis',
      synthesis.objetivo,
      synthesis.tema,
      JSON.stringify({
        principios_count: JSON.parse(synthesis.principios).length,
        experimentos_count: JSON.parse(synthesis.experimentos).length,
        sintesis_length: synthesis.sintesis_unificada.length
      }),
      synthesis.objetivo,
      synthesis.tema,
      synthesis.user_feedback,
      Date.now()
    ]);
  }
  
  async analyzeFailure(synthesisId, comment) {
    // Almacenar para an√°lisis posterior y reentrenamiento
    await db.run(`
      INSERT INTO ml_training_data (
        interaction_type,
        user_input,
        system_output,
        user_feedback,
        feedback_comment,
        timestamp,
        used_for_training
      ) VALUES (?, ?, ?, ?, ?, ?, 0)
    `, [
      'synthesis_failure',
      synthesisId,
      'synthesis_output',
      'negative',
      comment,
      Date.now()
    ]);
  }
}

module.exports = new GAPMemoryService();
```

---

### 3.5 Agent 5: Narrator (Voz de Autor/Coach)

```javascript
// backend/services/agents/narrator.js

const ollama = require('../../utils/ollama');
const db = require('../../database');

class NarratorAgent {
  
  constructor() {
    // Perfiles de voz por autor
    this.voices = {
      'ryan_holiday': {
        style: 'directo, estoico, usa historias de fil√≥sofos antiguos',
        tone: 'mentor experimentado pero accesible',
        signature_phrases: [
          'D√©jame contarte algo que aprend√≠ de los estoicos...',
          'La pregunta real aqu√≠ es...',
          'Esto me recuerda a...'
        ],
        avoid: ['listas de bullets', 'lenguaje acad√©mico', 'abstracciones sin ejemplos'],
        author_name: 'Ryan Holiday'
      },
      'james_clear': {
        style: 'cient√≠fico pero pr√°ctico, enfocado en sistemas y h√°bitos',
        tone: 'coach pragm√°tico y optimista',
        signature_phrases: [
          'Aqu√≠ est√° lo que la ciencia nos dice...',
          'El problema no es la motivaci√≥n, es...',
          'Haz esto tan peque√±o que...'
        ],
        avoid: ['teor√≠a sin pr√°ctica', 'complejidad innecesaria'],
        author_name: 'James Clear'
      },
      'naval_ravikant': {
        style: 'filos√≥fico, parad√≥jico, pensamiento en primeros principios',
        tone: 'sabio moderno, directo y provocador',
        signature_phrases: [
          'La verdadera pregunta es...',
          'Todo se reduce a...',
          'Si tuviera que elegir solo una cosa...'
        ],
        avoid: ['obviedades', 'consejos gen√©ricos', 'motivaci√≥n superficial'],
        author_name: 'Naval Ravikant'
      },
      'default_mentor': {
        style: 'conversacional, emp√°tico, claro',
        tone: 'mentor cercano y confiable',
        signature_phrases: [
          'D√©jame explicarte c√≥mo veo esto...',
          'La clave aqu√≠ est√° en...',
          'Pi√©nsalo de esta manera...'
        ],
        avoid: ['jerga t√©cnica', 'distancia acad√©mica', 'listas sin narrativa'],
        author_name: 'Coach'
      }
    };
  }
  
  /**
   * Obtener perfil de voz basado en el libro
   */
  async getVoiceProfile(bookId) {
    const book = await db.get('SELECT author FROM books WHERE id = ?', [bookId]);
    
    if (!book) return this.voices['default_mentor'];
    
    // Matching de autores
    const authorLower = book.author.toLowerCase();
    
    if (authorLower.includes('ryan holiday')) return this.voices['ryan_holiday'];
    if (authorLower.includes('james clear')) return this.voices['james_clear'];
    if (authorLower.includes('naval')) return this.voices['naval_ravikant'];
    
    return this.voices['default_mentor'];
  }
  
  /**
   * Generar respuesta narrativa (NO lista, NO bullets)
   */
  async generateNarrative(synthesis, userQuestion, bookId) {
    console.log(`‚úçÔ∏è  Narrator Agent ejecutando...`);
    
    const voiceProfile = await this.getVoiceProfile(bookId);
    
    const prompt = `Eres ${voiceProfile.author_name}, hablando directamente con alguien que te admira y busca aprender.

TU ESTILO:
- ${voiceProfile.style}
- Tono: ${voiceProfile.tone}
- Frases caracter√≠sticas: ${voiceProfile.signature_phrases.join(' / ')}

‚ùå NUNCA USES:
${voiceProfile.avoid.map(a => `- ${a}`).join('\n')}

CONOCIMIENTO SINTETIZADO:
${JSON.stringify(synthesis, null, 2)}

PREGUNTA DEL USUARIO:
"${userQuestion}"

ESCRIBE UNA RESPUESTA CONVERSACIONAL:

**ESTRUCTURA (sin headers visibles):**

1. APERTURA (1-2 p√°rrafos)
   - Conecta emp√°ticamente con la pregunta
   - Introduce el tema como si estuvieras conversando tomando caf√©
   - Usa tu voz caracter√≠stica desde el inicio

2. DESARROLLO (4-6 p√°rrafos)
   - Entreteje las ideas en narrativa fluida
   - USA met√°foras y ejemplos cotidianos
   - Los principios se mencionan DENTRO de p√°rrafos, NO como lista
   - Ejemplos: "Cuando te encuentres en X, la clave est√° en Y porque Z..."
   - Mant√©n tono conversacional: "D√©jame explicarte...", "Lo que he visto es..."

3. ACCIONES PR√ÅCTICAS (2 p√°rrafos)
   - Presenta los experimentos de 72h como parte de la conversaci√≥n
   - NO uses "Experimento 1:", usa narrativa: "Podr√≠as empezar por..."
   - M√°ximo 3 acciones concretas integradas en p√°rrafos

4. CIERRE (1 p√°rrafo + pregunta)
   - Resume el insight principal en 2-3 frases
   - Termina con UNA pregunta reflexiva que invite a pensar
   - La pregunta final DEBE ser: "¬øQu√© parte de esto quieres profundizar o aplicar primero?"

**REGLAS ABSOLUTAS:**
‚ùå CERO bullets (‚Ä¢, -, *, 1., 2., etc.)
‚ùå CERO listas numeradas
‚ùå CERO headers markdown (##, ###)
‚ùå CERO "En resumen...", "Los puntos clave son..."
‚ùå CERO "Espero que esto te sea √∫til"
‚úÖ SOLO p√°rrafos fluidos, narrativa natural
‚úÖ HABLA en segunda persona ("t√∫", "te")
‚úÖ USA ejemplos concretos y met√°foras
‚úÖ SUENA como mentor humano, NO como IA

Escribe SOLO la respuesta narrativa (sin meta-comentarios, sin markdown excepto p√°rrafos):
`;

    const response = await ollama.generate({
      model: 'llama3.1:70b',
      prompt,
      options: {
        temperature: 0.7,
        top_p: 0.9,
        num_ctx: 8192
      }
    });
    
    const narrative = response.response.trim();
    
    // Validaci√≥n autom√°tica (evitar bullets)
    const hasBullets = /[‚Ä¢\-\*]\s|^\d+\./m.test(narrative);
    const hasHeaders = /^#{1,6}\s/m.test(narrative);
    
    if (hasBullets || hasHeaders) {
      console.warn('‚ö†Ô∏è  Respuesta contiene bullets/headers, regenerando...');
      // TODO: Regenerar con prompt m√°s estricto
    }
    
    console.log(`‚úÖ Narrativa generada (${narrative.split(' ').length} palabras)`);
    
    return narrative;
  }
}

module.exports = new NarratorAgent();
```

---

## 4. Flujo Completo en n8n

### 4.1 Workflow Master - Pipeline Completo

```json
{
  "name": "AMROIS - Full Pipeline",
  "nodes": [
    {
      "parameters": {
        "httpMethod": "POST",
        "path": "full-pipeline",
        "responseMode": "responseNode"
      },
      "name": "Webhook Start",
      "type": "n8n-nodes-base.webhook",
      "position": [100, 300]
    },
    {
      "parameters": {
        "method": "POST",
        "url": "http://localhost:5678/webhook/interpret"
      },
      "name": "Agent 1 - Interpreter",
      "type": "n8n-nodes-base.httpRequest",
      "position": [320, 300]
    },
    {
      "parameters": {
        "method": "POST",
        "url": "http://localhost:3464/api/agents/extract"
      },
      "name": "Agent 2 - Extractor",
      "type": "n8n-nodes-base.httpRequest",
      "position": [540, 300]
    },
    {
      "parameters": {
        "method": "POST",
        "url": "http://localhost:3464/api/agents/analyze"
      },
      "name": "Agent 3 - Analyzer",
      "type": "n8n-nodes-base.httpRequest",
      "position": [760, 300]
    },
    {
      "parameters": {
        "method": "POST",
        "url": "http://localhost:3464/api/agents/synthesize"
      },
      "name": "Agent 4 - Synthesizer",
      "type": "n8n-nodes-base.httpRequest",
      "position": [980, 300]
    },
    {
      "parameters": {
        "method": "POST",
        "url": "http://localhost:3464/api/agents/narrate"
      },
      "name": "Agent 5 - Narrator",
      "type": "n8n-nodes-base.httpRequest",
      "position": [1200, 300]
    },
    {
      "parameters": {
        "respondWith": "json",
        "responseBody": "={{ $json }}"
      },
      "name": "Respond Final",
      "type": "n8n-nodes-base.respondToWebhook",
      "position": [1420, 300]
    }
  ],
  "connections": {
    "Webhook Start": {
      "main": [[{"node": "Agent 1 - Interpreter"}]]
    },
    "Agent 1 - Interpreter": {
      "main": [[{"node": "Agent 2 - Extractor"}]]
    },
    "Agent 2 - Extractor": {
      "main": [[{"node": "Agent 3 - Analyzer"}]]
    },
    "Agent 3 - Analyzer": {
      "main": [[{"node": "Agent 4 - Synthesizer"}]]
    },
    "Agent 4 - Synthesizer": {
      "main": [[{"node": "Agent 5 - Narrator"}]]
    },
    "Agent 5 - Narrator": {
      "main": [[{"node": "Respond Final"}]]
    }
  }
}
```

### 4.2 Endpoints de Agentes en Backend

```javascript
// backend/routes/agents.js (NUEVO)

const express = require('express');
const router = express.Router();

const extractorAgent = require('../services/agents/extractor');
const analyzerAgent = require('../services/agents/analyzer');
const synthesizerAgent = require('../services/agents/synthesizer');
const narratorAgent = require('../services/agents/narrator');

// Agent 2: Extractor
router.post('/extract', async (req, res) => {
  try {
    const { interpretation, message, bookId } = req.body;
    const result = await extractorAgent.extract(interpretation, message, bookId);
    res.json(result);
  } catch (error) {
    console.error('Error en Extractor:', error);
    res.status(500).json({ error: error.message });
  }
});

// Agent 3: Analyzer
router.post('/analyze', async (req, res) => {
  try {
    const { extraction, interpretation } = req.body;
    const result = await analyzerAgent.analyze(extraction.extraction, interpretation);
    res.json(result);
  } catch (error) {
    console.error('Error en Analyzer:', error);
    res.status(500).json({ error: error.message });
  }
});

// Agent 4: Synthesizer
router.post('/synthesize', async (req, res) => {
  try {
    const { analysis, interpretation, userContext } = req.body;
    const result = await synthesizerAgent.synthesize(analysis, interpretation, userContext);
    res.json(result);
  } catch (error) {
    console.error('Error en Synthesizer:', error);
    res.status(500).json({ error: error.message });
  }
});

// Agent 5: Narrator
router.post('/narrate', async (req, res) => {
  try {
    const { synthesis, originalMessage, bookId } = req.body;
    const narrative = await narratorAgent.generateNarrative(
      synthesis,
      originalMessage,
      bookId
    );
    
    res.json({
      narrative_response: narrative,
      synthesis_id: synthesis.id,
      next_question: "¬øQu√© parte de esto quieres profundizar o aplicar primero?"
    });
  } catch (error) {
    console.error('Error en Narrator:', error);
    res.status(500).json({ error: error.message });
  }
});

// Logging de interpretaci√≥n (para tracking)
router.post('/log-interpretation', async (req, res) => {
  try {
    const db = require('../database');
    await db.run(`
      INSERT INTO interpretations_log (
        interpretation_id,
        objective,
        clarity,
        depth,
        timestamp
      ) VALUES (?, ?, ?, ?, ?)
    `, [
      req.body.id,
      req.body.objetivo,
      req.body.claridad_suficiente ? 1 : 0,
      req.body.profundidad,
      Date.now()
    ]);
    res.json({ success: true });
  } catch (error) {
    console.error('Error logging interpretation:', error);
    res.status(500).json({ error: error.message });
  }
});

module.exports = router;
```

**Registrar en app.js:**

```javascript
// backend/app.js (MODIFICAR)

const agentsRoutes = require('./routes/agents');

// ... otras rutas ...

app.use('/api/agents', agentsRoutes);
```

---

## 5. Migraciones de Base de Datos

```sql
-- backend/migrations/002_add_agent_tables.sql

-- Tabla de interpretaciones (Agent 1)
CREATE TABLE IF NOT EXISTS interpretations_log (
  id INTEGER PRIMARY KEY AUTOINCREMENT,
  interpretation_id TEXT UNIQUE NOT NULL,
  objective TEXT NOT NULL,
  clarity INTEGER NOT NULL, -- 0 o 1
  depth TEXT NOT NULL,
  timestamp INTEGER NOT NULL
);

-- Tabla de extracciones (Agent 2)
CREATE TABLE IF NOT EXISTS extractions (
  id INTEGER PRIMARY KEY AUTOINCREMENT,
  book_id TEXT NOT NULL,
  query TEXT NOT NULL,
  extraction_data TEXT NOT NULL, -- JSON
  chunks_used INTEGER NOT NULL,
  created_at INTEGER NOT NULL,
  FOREIGN KEY (book_id) REFERENCES books(id)
);

-- Tabla GAP - Memoria de s√≠ntesis (Agent 4)
CREATE TABLE IF NOT EXISTS gap_synthesis_memory (
  id INTEGER PRIMARY KEY AUTOINCREMENT,
  synthesis_id TEXT UNIQUE NOT NULL,
  objetivo TEXT NOT NULL,
  tema TEXT NOT NULL,
  profundidad TEXT,
  sintesis_unificada TEXT NOT NULL,
  principios TEXT NOT NULL, -- JSON
  experimentos TEXT NOT NULL, -- JSON
  timestamp INTEGER NOT NULL,
  user_feedback INTEGER, -- 1-5 stars
  feedback_comment TEXT,
  feedback_timestamp INTEGER
);

-- Tabla GAP - Patrones exitosos
CREATE TABLE IF NOT EXISTS gap_success_patterns (
  id INTEGER PRIMARY KEY AUTOINCREMENT,
  pattern_type TEXT NOT NULL,
  objetivo TEXT NOT NULL,
  tema TEXT,
  successful_structure TEXT NOT NULL, -- JSON
  times_used INTEGER DEFAULT 1,
  avg_rating REAL,
  last_updated INTEGER NOT NULL
);

-- Tabla para ML training data
CREATE TABLE IF NOT EXISTS ml_training_data (
  id INTEGER PRIMARY KEY AUTOINCREMENT,
  interaction_type TEXT NOT NULL,
  user_input TEXT NOT NULL,
  system_output TEXT NOT NULL,
  user_feedback TEXT,
  feedback_comment TEXT,
  timestamp INTEGER NOT NULL,
  used_for_training INTEGER DEFAULT 0
);

-- Tabla de m√©tricas de calidad
CREATE TABLE IF NOT EXISTS quality_metrics (
  id INTEGER PRIMARY KEY AUTOINCREMENT,
  synthesis_id TEXT,
  has_bullets INTEGER,
  ends_with_question INTEGER,
  uses_second_person INTEGER,
  avoids_ai_words INTEGER,
  word_count INTEGER,
  readability_score REAL,
  timestamp INTEGER NOT NULL,
  FOREIGN KEY (synthesis_id) REFERENCES gap_synthesis_memory(synthesis_id)
);

-- Agregar columna a books para tracking de vector indexing
ALTER TABLE books ADD COLUMN vector_indexed INTEGER DEFAULT 0;
ALTER TABLE books ADD COLUMN chunks_count INTEGER DEFAULT 0;

-- √çndices para performance
CREATE INDEX idx_interpretations_timestamp ON interpretations_log(timestamp);
CREATE INDEX idx_extractions_book ON extractions(book_id);
CREATE INDEX idx_gap_feedback ON gap_synthesis_memory(user_feedback);
CREATE INDEX idx_gap_objetivo ON gap_synthesis_memory(objetivo);
CREATE INDEX idx_ml_training_type ON ml_training_data(interaction_type);
CREATE INDEX idx_quality_synthesis ON quality_metrics(synthesis_id);
```

**Script de ejecuci√≥n:**

```javascript
// backend/scripts/run-migrations.js

const db = require('../database');
const fs = require('fs');
const path = require('path');

async function runMigrations() {
  const migrationsDir = path.join(__dirname, '../migrations');
  const files = fs.readdirSync(migrationsDir)
    .filter(f => f.endsWith('.sql'))
    .sort();
  
  console.log('üîÑ Ejecutando migraciones...\n');
  
  for (const file of files) {
    console.log(`  - ${file}`);
    const sql = fs.readFileSync(path.join(migrationsDir, file), 'utf8');
    
    try {
      await db.exec(sql);
      console.log(`    ‚úÖ Ejecutada`);
    } catch (error) {
      console.error(`    ‚ùå Error:`, error.message);
    }
  }
  
  console.log('\nüéâ Migraciones completadas');
}

runMigrations().catch(console.error);
```

---

## 6. Frontend - Componentes Nuevos

### 6.1 Feedback Component

```jsx
// frontend/src/components/MessageFeedback.jsx

import React, { useState } from 'react';
import { StarOutlined, StarFilled } from '@ant-design/icons';
import { Input, Button, message as antMessage } from 'antd';
import './MessageFeedback.css';

export default function MessageFeedback({ synthesisId, onFeedbackSubmit }) {
  const [rating, setRating] = useState(0);
  const [comment, setComment] = useState('');
  const [submitted, setSubmitted] = useState(false);
  const [loading, setLoading] = useState(false);
  
  const handleSubmit = async () => {
    if (rating === 0) {
      antMessage.warning('Por favor selecciona una calificaci√≥n');
      return;
    }
    
    setLoading(true);
    
    try {
      const response = await fetch('/api/chat/feedback', {
        method: 'POST',
        headers: { 'Content-Type': 'application/json' },
        body: JSON.stringify({
          synthesis_id: synthesisId,
          rating,
          comment: comment.trim() || null
        })
      });
      
      if (!response.ok) throw new Error('Error al enviar feedback');
      
      setSubmitted(true);
      antMessage.success('¬°Gracias por tu feedback!');
      
      if (onFeedbackSubmit) {
        onFeedbackSubmit(rating, comment);
      }
    } catch (error) {
      console.error('Error submitting feedback:', error);
      antMessage.error('Error al enviar feedback');
    } finally {
      setLoading(false);
    }
  };
  
  if (submitted) {
    return (
      <div className="feedback-thanks">
        ‚úÖ Gracias por tu feedback. Esto ayuda a mejorar las respuestas.
      </div>
    );
  }
  
  return (
    <div className="message-feedback">
      <div className="feedback-label">¬øQu√© tan √∫til fue esta respuesta?</div>
      
      <div className="rating-stars">
        {[1, 2, 3, 4, 5].map(star => (
          <span
            key={star}
            onClick={() => setRating(star)}
            className={`star ${star <= rating ? 'filled' : ''}`}
          >
            {star <= rating ? <StarFilled /> : <StarOutlined />}
          </span>
        ))}
      </div>
      
      {rating > 0 && (
        <div className="feedback-input">
          <Input.TextArea
            placeholder={
              rating >= 4 
                ? "Opcional: ¬øQu√© fue lo m√°s √∫til?" 
                : "Opcional: ¬øQu√© podr√≠a mejorar?"
            }
            value={comment}
            onChange={(e) => setComment(e.target.value)}
            rows={3}
            maxLength={500}
          />
          <Button
            type="primary"
            onClick={handleSubmit}
            loading={loading}
            style={{ marginTop: '8px' }}
          >
            Enviar Feedback
          </Button>
        </div>
      )}
    </div>
  );
}
```

```css
/* frontend/src/components/MessageFeedback.css */

.message-feedback {
  margin-top: 16px;
  padding: 12px;
  background: #f5f5f5;
  border-radius: 8px;
}

.feedback-label {
  font-size: 13px;
  color: #666;
  margin-bottom: 8px;
}

.rating-stars {
  display: flex;
  gap: 8px;
}

.rating-stars .star {
  font-size: 24px;
  cursor: pointer;
  transition: all 0.2s;
  color: #d9d9d9;
}

.rating-stars .star.filled {
  color: #faad14;
}

.rating-stars .star:hover {
  transform: scale(1.1);
}

.feedback-input {
  margin-top: 12px;
}

.feedback-thanks {
  margin-top: 12px;
  padding: 8px 12px;
  background: #f6ffed;
  border: 1px solid #b7eb8f;
  border-radius: 4px;
  color: #52c41a;
  font-size: 13px;
}
```

### 6.2 Agent Processing Indicator

```jsx
// frontend/src/components/AgentProcessingIndicator.jsx

import React from 'react';
import { Spin, Steps } from 'antd';
import {
  SearchOutlined,
  ExperimentOutlined,
  BulbOutlined,
  EditOutlined,
  CheckCircleOutlined
} from '@ant-design/icons';
import './AgentProcessingIndicator.css';

export default function AgentProcessingIndicator({ currentStep = 0 }) {
  const steps = [
    {
      title: 'Interpretando',
      description: 'Analizando tu pregunta',
      icon: <SearchOutlined />
    },
    {
      title: 'Extrayendo',
      description: 'Buscando en el libro',
      icon: <ExperimentOutlined />
    },
    {
      title: 'Analizando',
      description: 'Aplicando frameworks',
      icon: <BulbOutlined />
    },
    {
      title: 'Sintetizando',
      description: 'Creando marco mental',
      icon: <EditOutlined />
    },
    {
      title: 'Respondiendo',
      description: 'Generando respuesta',
      icon: <CheckCircleOutlined />
    }
  ];
  
  return (
    <div className="agent-processing">
      <div className="processing-header">
        <Spin />
        <span className="processing-text">Coach AI procesando...</span>
      </div>
      
      <Steps
        current={currentStep}
        size="small"
        items={steps}
        className="agent-steps"
      />
      
      <div className="processing-info">
        {steps[currentStep].description}
      </div>
    </div>
  );
}
```

```css
/* frontend/src/components/AgentProcessingIndicator.css */

.agent-processing {
  padding: 20px;
  background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
  border-radius: 12px;
  color: white;
}

.processing-header {
  display: flex;
  align-items: center;
  gap: 12px;
  margin-bottom: 16px;
}

.processing-text {
  font-size: 16px;
  font-weight: 500;
}

.agent-steps {
  margin: 16px 0;
}

.agent-steps :global(.ant-steps-item-title) {
  color: rgba(255, 255, 255, 0.85) !important;
}

.agent-steps :global(.ant-steps-item-description) {
  color: rgba(255, 255, 255, 0.65) !important;
}

.agent-steps :global(.ant-steps-item-finish .ant-steps-item-icon) {
  background-color: #52c41a !important;
  border-color: #52c41a !important;
}

.processing-info {
  text-align: center;
  font-size: 14px;
  opacity: 0.9;
  margin-top: 12px;
}
```

### 6.3 Integrar en ChatMessage

```jsx
// frontend/src/components/ChatMessage.jsx (MODIFICAR)

import React from 'react';
import MessageFeedback from './MessageFeedback';
import './ChatMessage.css';

export default function ChatMessage({ message, isLast }) {
  // Detectar si es respuesta del agente con synthesis_id
  const showFeedback = 
    message.role === 'assistant' && 
    message.metadata?.synthesis_id && 
    isLast;
  
  return (
    <div className={`chat-message ${message.role}`}>
      <div className="message-content">
        {/* Renderizar con formato de p√°rrafos */}
        {message.content.split('\n\n').map((paragraph, i) => (
          <p key={i}>{paragraph}</p>
        ))}
      </div>
      
      {message.metadata?.voice_profile && (
        <div className="message-meta">
          <span className="voice-profile">
            üé≠ Voz: {message.metadata.voice_profile}
          </span>
        </div>
      )}
      
      {showFeedback && (
        <MessageFeedback
          synthesisId={message.metadata.synthesis_id}
          onFeedbackSubmit={(rating, comment) => {
            console.log('Feedback:', rating, comment);
            // Opcional: actualizar estado local
          }}
        />
      )}
    </div>
  );
}
```

---

## 7. Plan de Implementaci√≥n Gradual

### Fase 1: Fundaci√≥n (Semana 1-2)

**Objetivo:** Preparar infraestructura sin romper nada

**Tareas:**
1. ‚úÖ Instalar n8n (Docker)
2. ‚úÖ Instalar Chroma (Docker)
3. ‚úÖ Ejecutar migraciones SQL
4. ‚úÖ Crear servicios base (vectorStore, gapMemory)
5. ‚úÖ Feature flag `USE_MULTI_AGENT=false`

**Validaci√≥n:**
- Sistema actual funciona normal
- n8n accesible en :5678
- Chroma accesible en :8000
- Tablas nuevas creadas en SQLite

### Fase 2: Vector Store (Semana 3)

**Objetivo:** Migrar RAG a Chroma

**Tareas:**
1. ‚úÖ Implementar `vectorStore.js`
2. ‚úÖ Script de migraci√≥n de libros
3. ‚úÖ Re-indexar libros existentes
4. ‚úÖ Comparar resultados b√∫squeda (vieja vs nueva)
5. ‚úÖ Ajustar chunking si es necesario

**Validaci√≥n:**
- B√∫squeda en Chroma retorna resultados relevantes
- Tiempo de indexaci√≥n aceptable (<5 min por libro)
- Similarity scores >0.7 en queries de prueba

### Fase 3: Agent 1 (Interpreter) - Semana 4

**Objetivo:** Clasificaci√≥n de intenciones funcional

**Tareas:**
1. ‚úÖ Crear workflow n8n para Agent 1
2. ‚úÖ Implementar endpoint `/api/agents/interpret` (via n8n)
3. ‚úÖ Integrar en `/api/chat/book/:id` con feature flag
4. ‚úÖ Testing manual con 20 preguntas variadas
5. ‚úÖ Ajustar prompts seg√∫n resultados

**Validaci√≥n:**
- Precisi√≥n >80% en clasificaci√≥n de objetivo
- Detecta correctamente cuando falta claridad
- Preguntas de aclaraci√≥n son relevantes

### Fase 4: Agents 2-3-4 (Extract-Analyze-Synthesize) - Semana 5-6

**Objetivo:** Pipeline de an√°lisis completo

**Tareas:**
1. ‚úÖ Implementar Agent 2 (Extractor)
2. ‚úÖ Implementar Agent 3 (Analyzer)
3. ‚úÖ Implementar Agent 4 (Synthesizer)
4. ‚úÖ Implementar GAP Memory
5. ‚úÖ Workflow n8n completo (5 agentes)
6. ‚úÖ Testing end-to-end

**Validaci√≥n:**
- Pipeline ejecuta en <30 segundos
- S√≠ntesis tiene estructura correcta
- GAP almacena correctamente

### Fase 5: Agent 5 (Narrator) - Semana 7

**Objetivo:** Voz humana y personalizaci√≥n

**Tareas:**
1. ‚úÖ Implementar Agent 5 (Narrator)
2. ‚úÖ Configurar voces por autor
3. ‚úÖ Validar que NO usa bullets
4. ‚úÖ Testing de calidad narrativa
5. ‚úÖ Ajustar prompts de voz

**Validaci√≥n:**
- 0% de respuestas con bullets
- Calidad narrativa >80/100
- Usuarios reportan "suena natural"

### Fase 6: Feedback & Learning - Semana 8

**Objetivo:** Sistema de mejora continua

**Tareas:**
1. ‚úÖ Frontend: componente de feedback
2. ‚úÖ Backend: endpoint de feedback
3. ‚úÖ Almacenamiento en GAP
4. ‚úÖ Dashboard de m√©tricas b√°sico
5. ‚úÖ Documentaci√≥n

**Validaci√≥n:**
- Feedback funciona end-to-end
- GAP aprende de ratings altos
- M√©tricas visibles en dashboard

### Fase 7: Activaci√≥n & Monitoreo - Semana 9

**Objetivo:** Ir a producci√≥n con multi-agente

**Tareas:**
1. ‚úÖ `USE_MULTI_AGENT=true` en producci√≥n
2. ‚úÖ Monitoreo de tiempos de respuesta
3. ‚úÖ An√°lisis de primeros 100 usos
4. ‚úÖ Ajustes basados en feedback real
5. ‚úÖ Documentaci√≥n de uso

---

## 8. Comandos √ötiles

### Instalaci√≥n de Dependencias

```bash
# Backend
cd backend
npm install chromadb @tensorflow/tfjs-node

# n8n (Docker)
docker run -d --restart=always \
  --name n8n \
  -p 5678:5678 \
  -v ~/.n8n:/home/node/.n8n \
  n8nio/n8n

# Chroma (Docker)
docker run -d --restart=always \
  --name chromadb \
  -p 8000:8000 \
  -v ./chroma_data:/chroma/chroma \
  chromadb/chroma:latest
```

### Scripts de Desarrollo

```bash
# Ejecutar migraciones
node backend/scripts/run-migrations.js

# Re-indexar todos los libros
node backend/scripts/migrate-to-vector-store.js

# Re-indexar un libro espec√≠fico
node backend/scripts/reindex-book.js --bookId=abc123

# Testear Agent 1
curl -X POST http://localhost:5678/webhook/interpret \
  -H "Content-Type: application/json" \
  -d '{"message": "Quiero aprender sobre h√°bitos", "bookId": "123"}'

# Testear pipeline completo
curl -X POST http://localhost:5678/webhook/full-pipeline \
  -H "Content-Type: application/json" \
  -d '{
    "interpretation": {...},
    "originalMessage": "...",
    "bookId": "123"
  }'
```

### Monitoreo

```bash
# Ver logs de n8n
docker logs -f n8n

# Ver logs de Chroma
docker logs -f chromadb

# Ver logs del backend
tail -f backend/logs/app.log

# Verificar Ollama
curl http://localhost:11434/api/tags
```

---

## 9. Troubleshooting

### Problema: n8n workflows no ejecutan

**S√≠ntomas:** Timeout, "Workflow not found"

**Soluci√≥n:**
```bash
# Reiniciar n8n
docker restart n8n

# Verificar logs
docker logs n8n

# Importar workflows manualmente desde UI
# ‚Üí n8n:5678 ‚Üí Import Workflow ‚Üí pegar JSON
```

### Problema: Chroma no indexa correctamente

**S√≠ntomas:** B√∫squedas vac√≠as, errores de embedding

**Soluci√≥n:**
```bash
# Verificar que Chroma est√© corriendo
curl http://localhost:8000/api/v1/heartbeat

# Limpiar y re-crear colecci√≥n
# Ver backend/scripts/reset-chroma.js

# Verificar embeddings de Ollama
curl -X POST http://localhost:11434/api/embeddings \
  -d '{"model": "llama3.1:70b", "prompt": "test"}'
```

### Problema: Respuestas lentas (>30 seg)

**S√≠ntomas:** Pipeline tarda mucho

**Diagn√≥stico:**
```javascript
// Agregar logging de tiempos en cada agente
console.time('Agent 2 - Extractor');
// ... c√≥digo ...
console.timeEnd('Agent 2 - Extractor');
```

**Optimizaciones:**
- Reducir `num_ctx` en Ollama (de 8192 a 4096)
- Usar modelo m√°s peque√±o para Analyzer (`llama3.1:8b`)
- Limitar chunks en Extractor (de 15 a 10)
- Cachear embeddings frecuentes

---

## 10. Pr√≥ximos Pasos Post-Implementaci√≥n

### Versi√≥n 2.1 (3 meses)
- [ ] Multi-libro: analizar 2-3 libros simult√°neamente
- [ ] M√°s voces: agregar 10+ autores (Naval, Taleb, etc.)
- [ ] Export a PDF/Notion de s√≠ntesis
- [ ] Planes 30/60/90 d√≠as autom√°ticos

### Versi√≥n 2.2 (6 meses)
- [ ] TensorFlow fine-tuning de voces
- [ ] Modo "debate" (2 autores dialogan)
- [ ] An√°lisis de PDFs t√©cnicos (papers, docs)
- [ ] API p√∫blica para integraciones

### Versi√≥n 3.0 (12 meses)
- [ ] Multi-idioma (ingl√©s, portugu√©s)
- [ ] An√°lisis de videos/podcasts
- [ ] Mobile apps nativas
- [ ] Marketplace de "coaches" especializados

---

## 11. Resumen Ejecutivo

**¬øQu√© cambia con AMROIS 2.0?**

| Antes (1.0) | Despu√©s (2.0) |
|------------|--------------|
| Respuesta tipo resumen | Conversaci√≥n tipo mentor |
| RAG b√°sico (chunks fijos) | Vector store sem√°ntico |
| Un solo flujo de an√°lisis | 5 agentes especializados |
| Sin memoria | GAP aprende de feedback |
| Voz gen√©rica | Voz por autor |
| Sin aprendizaje | Mejora continua con TF |

**¬øQu√© NO cambia?**
- ‚úÖ Stack base (Node + React + SQLite + Ollama)
- ‚úÖ Funcionalidades actuales (CRUD libros, visualizador)
- ‚úÖ Costo $0 en IA (sigue siendo local)

**¬øCu√°ndo estar√° listo?**
- MVP multi-agente: 4 semanas
- Con feedback y aprendizaje: 8 semanas
- Producci√≥n completa: 9 semanas

---

## 12. Checklist Pre-Deploy

```
BACKEND:
[ ] Migraciones ejecutadas
[ ] Vector store con >5 libros indexados
[ ] n8n workflows importados y testeados
[ ] Ollama con modelo correcto (llama3.1:70b)
[ ] Feature flags configurados (.env)
[ ] Logs funcionando

FRONTEND:
[ ] Componentes de feedback integrados
[ ] Indicador de agentes funcionando
[ ] Build de producci√≥n testeado
[ ] Variables de entorno correctas

INFRAESTRUCTURA:
[ ] Docker containers corriendo (n8n, Chroma)
[ ] Backup de BD programado
[ ] Monitoreo b√°sico (logs, tiempos)
[ ] SSL/HTTPS configurado (si aplica)

TESTING:
[ ] 20+ conversaciones de prueba exitosas
[ ] Validaci√≥n de calidad narrativa (sin bullets)
[ ] Tiempos <30 seg en P95
[ ] Feedback end-to-end funcional
```

---

**Este documento es la especificaci√≥n completa para evolucionar AMROIS 1.0 ‚Üí 2.0 manteniendo todo lo que funciona y agregando inteligencia multi-agente.**

¬øQuieres que profundice en alguna secci√≥n espec√≠fica, o generamos c√≥digo adicional para alg√∫n componente?
